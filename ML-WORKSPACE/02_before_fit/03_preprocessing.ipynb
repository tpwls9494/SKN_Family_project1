{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing (전처리)\n",
    "- Data cleaning\n",
    "- Data Encoding         : 텍스트 데이터 → 숫자로 변환 (범주형 데이터)\n",
    "- Data Scaling          : 숫자값 정규화\n",
    "- Outlier               : 이상치\n",
    "- Feature Engineering   : 속성 생성/수정/가공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoder\n",
    "- 범주형 데이터에 대해 적절히 숫자로 변환하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### one-hot Encoder\n",
    "- 주어진 데이터를 희소배열로 변환 (One-vs-Rest 배열)\n",
    "- 희소배열이란 대부분이 0이고 특정 인덱스만 값을 가지고 있는 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items = ['TV', '냉장고', '세탁기', '컴퓨터', '전기난로', '컴퓨터', 'TV', '믹서기', '컴퓨터']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "encoder.fit(items)\n",
    "encoded_items = encoder.transform(items)\n",
    "len(encoded_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot Encoder\n",
    "- 주어진 데이터를 희소배열로 변환 (One-vs-Rest 배열)\n",
    "- 희소배열이란 대부분이 0이고 특정 인덱스만 값을 가지고 있는 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 2차원 형태로 변환\n",
    "items = np.array(items).reshape(-1, 1)\n",
    "\n",
    "# One-hot encoding\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "encoder.fit(items)      # 중복값을 제거, 오름차순 정렬 -> 그 인데스에만 1을 준 희소행렬\n",
    "oh_items = encoder.transform(items)\n",
    "print(oh_items.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DataFrame에서 One-hot encoding 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'items': ['TV', '냉장고', '세탁기', '컴퓨터', '전기난로', '컴퓨터', 'TV', '믹서기', '컴퓨터']\n",
    "    })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(df, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame -> ndarray 변환\n",
    "# df_dummies.to_numpy()\n",
    "np.array(df_dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Scaling (Feature Scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 표준정규화 (StandardScaler)\n",
    "- 평균이 0, 표준편차가 1인 값으로\n",
    "- 이상치에 덜 민감하고, 선형회귀 및 로지스틱 회귀 등의 알고리즘에 적합\n",
    "- 데이터가 정규분포인 경우 더욱 적합함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 최소최대정규화 (MinMaxScaler)\n",
    "- 0~1 사이의 값으로 변환\n",
    "- SVM 및 KNN과 같은 거리 기반 모델에 적합\n",
    "- 이상치에 민감하게 반응, 이상치가 있는 경우 데이터 왜곡 가능성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Scaling (Feature Scaling)\n",
    "- scaling 작업은 train 데이터, test 데이터에 동일하게 적용해야 함\n",
    "- fit(): train 데이터\n",
    "- transform(): train 데이터, test 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_ds = load_iris()\n",
    "print(iris_ds.feature_names)\n",
    "iris_ds.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "standard_sc = StandardScaler()\n",
    "standard_sc.fit(iris_ds.data)\n",
    "standard_sc.transform(iris_ds.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minmax_sc = MinMaxScaler()\n",
    "# minmax_sc.fit_transform([[20], [30], [40]])\n",
    "minmax_sc.fit(iris_ds.data)\n",
    "minmax_sc.transform(iris_ds.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 타이타닉 생존율 예측에 필요한 전처리 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/titanic.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 -> 함수\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def fillna(df):\n",
    "    \"\"\"\n",
    "    결측치 처리 함수\n",
    "    - Age: 평균치로 대체\n",
    "    - Cabin: 'N' 기본값으로 대체\n",
    "    - Emberked: 'N' 기본값으로 대체\n",
    "    \"\"\"\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "    df['Cabin'] = df['Cabin'].fillna('N')\n",
    "    df['Embarked'] = df['Embarked'].fillna('N')\n",
    "    return df\n",
    "\n",
    "def drop_feature(df):\n",
    "    \"\"\"\n",
    "    모델 훈련과 관련 없는 속성 제거:\n",
    "    - passengerId, Name, Ticket\n",
    "    \"\"\"\n",
    "    return df.drop(['PassengerId', 'Name', 'Ticket'], axis=1) \n",
    "\n",
    "def encode_feather(df):\n",
    "    \"\"\"\n",
    "    범주형 데이터를 숫자로 인코딩\n",
    "    - Sex, Cabin, Embarked\n",
    "    \"\"\"\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    categories = ['Sex', 'Cabin', 'Embarked']\n",
    "    for cate_item in categories:\n",
    "        label_encoding = LabelEncoder()\n",
    "        df[cate_item] = label_encoding.fit_transform(df[cate_item])\n",
    "    return df\n",
    "\n",
    "def scailing_feature(train_data, test_data):\n",
    "    \"\"\"\n",
    "    특성 스케일링\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    train_scaled = scaler.fit_transform(train_data)\n",
    "    test_scaled = scaler.transform(test_data)\n",
    "    return train_scaled, test_scaled\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df = drop_feature(df)\n",
    "    df = fillna(df)\n",
    "    df = encode_feather(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수 호출\n",
    "df = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련-테스트 데이터 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 입력-라벨 데이터 분리\n",
    "titanic_input = df.drop(['Survived'], axis=1)\n",
    "titanic_label = df['Survived']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(titanic_input, titanic_label, test_size=.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 스케일링\n",
    "x_scaled_train, x_scaled_test = scailing_feature(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logisticRegression 훈련\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_classifier = LogisticRegression()\n",
    "lr_classifier.fit(x_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가\n",
    "lr_classifier.score(x_scaled_train, y_train), lr_classifier.score(x_scaled_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
